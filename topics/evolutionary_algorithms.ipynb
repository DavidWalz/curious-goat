{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Algorithms\n",
    "\n",
    "Evolutionary algorithms are a family of population-based and typically gradient-free optimization methods for non-linear / non-convex functions in high dimensions. Certain variants are well suited for multi-objective optimization as population converges to sampling the Pareto front.\n",
    "\n",
    "* [Differential evolution](#Differential-evolution)\n",
    "* [Particle swarm optimization](#Particle-swarm-optimization)\n",
    "* [Genetic algorithms](#Genetic-algorithms)\n",
    "* [CMA-ES](#CMA-ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to consider the fixed-size vector encoding of an individual as its genes. Individuals are selected and paired according to their fitness, and offsprings are created by a crossover operation of the parents genes with some mutations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to loop over individuals and\n",
    "* (mutation) randomly pick 3 other individuals $a, b, c$ from population to construct new traits as $x_n = a + (b - c) \\times F$ where $F$ is the mutation rate\n",
    "* (crossover) randomly accept new traits into the individual according to crossover probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99931034e-01, 3.38251861e-05, 2.24834883e-05])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minimize_de(function, bounds, steps=50, n=20, mutation=0.5, crossover=0.7):\n",
    "    \"\"\"Differential evolution optimization\n",
    "    \n",
    "    Args:\n",
    "        function: callable f(x) to be minimized\n",
    "        bounds: box bounds of the input space [[lower bounds], [upper bounds]]\n",
    "        steps: number of optimization steps\n",
    "        n: population size, >= 4\n",
    "        mutation: mutation rate / differential weight, typically (0 - 2]\n",
    "        crossover: crossover probability\n",
    "        \n",
    "    Returns:\n",
    "        x_min: the best inputs found\n",
    "    \"\"\"\n",
    "    lower, upper = bounds\n",
    "    d = len(lower)  # number of inputs\n",
    "    \n",
    "    population = np.random.uniform(lower, upper, size=(n, d))\n",
    "            \n",
    "    for i in range(steps):\n",
    "        \n",
    "        # loop over individuals in the population\n",
    "        for j, x_target in enumerate(population):\n",
    "            \n",
    "            # mutation\n",
    "            candidates = list(range(n))\n",
    "            candidates.remove(j)\n",
    "            x1, x2, x3 = population[np.random.choice(candidates, size=3, replace=False)]\n",
    "            x_new = x1 + (x2 - x3) * mutation\n",
    "            x_new = np.clip(x_new, lower, upper)\n",
    "\n",
    "            # cross-over\n",
    "            x_new = np.where(np.random.rand(d) < crossover, x_new, x_target)\n",
    "                    \n",
    "            # selection\n",
    "            if function(x_new) < function(x_target):\n",
    "                population[j] = x_new\n",
    "\n",
    "    best = np.argmin(function(population))\n",
    "    return population[best]\n",
    "\n",
    "\n",
    "def some_function(x):\n",
    "    return np.sum((x - [1, 0, 0])**2, axis=-1)\n",
    "\n",
    "minimize_de(some_function, bounds=[[-2, -2, -2], [2, 2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle swarm optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that individuals (called particles here) start walking in a random direction but are pulled towards their own best known optimum and the best known optimum of the swarm.\n",
    "\n",
    "Basic implemtation according https://en.wikipedia.org/wiki/Particle_swarm_optimization#Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00122578e+00, -5.14263650e-03,  3.90900545e-04])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minimize_pso(function, bounds, steps=50, n=20, ω=0.5, φ1=0.2, φ2=0.2):\n",
    "    \"\"\"Particle swarm optimization\n",
    "    \n",
    "    Args:\n",
    "        function: callable f(x) to be minimized\n",
    "        bounds: box bounds of the input space [[lower bounds], [upper bounds]]\n",
    "        steps: number of optimization steps\n",
    "        n: population size\n",
    "        ω: inertia\n",
    "        φ1: pull towards particle's best knwown position\n",
    "        φ2: pull towards swarm's best known position\n",
    "\n",
    "    Returns:\n",
    "        x_min: the best inputs found\n",
    "    \"\"\"\n",
    "    lower, upper = bounds\n",
    "    d = len(lower)  # number of inputs\n",
    "    \n",
    "    # initial position and velocity\n",
    "    X = np.random.uniform(lower, upper, size=(n, d))\n",
    "    V = np.random.uniform(-1, 1, size=(n, d)) * (upper - lower)\n",
    "\n",
    "    # best known position\n",
    "    X_best = X.copy()\n",
    "    \n",
    "    # swarm's best known position\n",
    "    x_swarm = X[np.argmin(function(X))]\n",
    "    \n",
    "    # while termination criterion not met\n",
    "    for _ in range(steps):\n",
    "        \n",
    "        # loop over particles\n",
    "        for i in range(n):\n",
    "            \n",
    "            # update velocity\n",
    "            r1 = np.random.uniform(0, φ1, size=d)\n",
    "            r2 = np.random.uniform(0, φ2, size=d)\n",
    "            V[i] = ω * V[i] + r1 * (X_best[i] - X[i]) + r2 * (x_swarm - X[i])\n",
    "            \n",
    "            # update position\n",
    "            X[i] = np.clip(X[i] + V[i], lower, upper)\n",
    "            \n",
    "            # update the particles best known position\n",
    "            if function(X[i]) < function(X_best[i]):\n",
    "                X_best[i] = X[i]\n",
    "            \n",
    "            # update the swarms best known position\n",
    "            if function(X_best[i]) < function(x_swarm):\n",
    "                x_swarm = X_best[i]\n",
    "\n",
    "    return x_swarm\n",
    "\n",
    "\n",
    "def some_function(x):\n",
    "    return np.sum((x - [1, 0, 0])**2, axis=-1)\n",
    "\n",
    "bounds = np.array([[-2, -2, -2], [2, 2, 2]])\n",
    "minimize_pso(some_function, bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA-ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Covariance matrix adaption evolution strategy](https://en.wikipedia.org/wiki/CMA-ES)  \n",
    "\n",
    "In an evolution strategy, new candidate solutions are sampled according to a multivariate normal distribution. \n",
    "Recombination amounts to selecting a new mean value for the distribution.\n",
    "Mutation amounts to adding a random perturbation. \n",
    "Pairwise dependencies between the variables in the distribution are represented by a covariance matrix.\n",
    "The covariance matrix adaptation (CMA) is a method to update the covariance matrix of this distribution\n",
    "\n",
    "In the commonly used (μ/μw, λ)-CMA-ES in each iteration step a weighted combination of the μ best out of λ new candidate solutions is used to update the distribution parameters.\n",
    "\n",
    "Links\n",
    "* tutorial https://arxiv.org/abs/1604.00772  \n",
    "* pure python implemention in pycma https://github.com/CMA-ES/pycma/blob/master/cma/evolution_strategy.py  \n",
    "* CMA in DEAP https://github.com/DEAP/deap/blob/master/deap/cma.py  \n",
    "* CMA in TF https://github.com/srom/cma-es/blob/master/cma/core.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8289815827383844\n",
      "0.08477170170794752\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(5)\n",
    "print(np.sum(a)**2 / np.sum(a**2))\n",
    "print(np.var(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_cma(function, bounds, steps=100):\n",
    "    lower, upper = bounds\n",
    "    d = len(lower)  # number of inputs\n",
    "      \n",
    "    xmean = np.random.randn(d)\n",
    "    σ = 0.3  # step size, coordinate wise standard deviation\n",
    "    λ = 4 + np.floor(3 * np.log(d))  # population size, offspring number\n",
    "    μ = np.floor(λ / 2)  # number of surviving individuals from one generation to the next\n",
    "    \n",
    "    # Recombination weights\n",
    "    weights = np.concat([\n",
    "            np.log(μ + 0.5) - np.log(np.arange(1, μ + 1)),\n",
    "            np.zeros(λ - μ),\n",
    "        ], axis=0)\n",
    "    # Normalize weights such as they sum to one and reshape into a column matrix\n",
    "    weights = (weights / np.sum(weights))[:, np.newaxis]\n",
    "        \n",
    "    # Variance-effective size of mu\n",
    "    μeff = np.sum(weights) ** 2 / np.sum(weights ** 2)\n",
    "        \n",
    "    # Time constant for cumulation for C\n",
    "    cc = (4 + self.μeff / self.N) / (self.N + 4 + 2 * self.μeff / self.N)\n",
    "        \n",
    "        # Time constant for cumulation for sigma control\n",
    "        self.cσ = (self.μeff + 2) / (self.N + self.μeff + 5)\n",
    "        \n",
    "        # Learning rate for rank-one update of C\n",
    "        self.c1 = 2 / ((self.N + 1.3)**2 + self.μeff)\n",
    "        \n",
    "        # Learning rate for rank-μ update of C\n",
    "        self.cμ = tf.constant(self._cμ, dtype=tf.float64)\n",
    "        else:\n",
    "            self.cμ = 2 * (self.μeff - 2 + 1 / self.μeff) / ((self.N + 2)**2 + 2 * self.μeff / 2)\n",
    "        # Damping for sigma\n",
    "        damps = (\n",
    "                1 + 2 * tf.maximum(0, tf.sqrt((self.μeff - 1) / (self.N + 1)) - 1) + self.cσ\n",
    "            )\n",
    "        # Expectation of ||N(0,I)||\n",
    "        self.chiN = tf.sqrt(self.N) * (1 - 1 / (4 * self.N) + 1 / (21 * self.N**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
