{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Optimization (BO) is a method for the optimization of expensive black-box functions by means of a probabilistic surrogate model and an acquisition function that specifies a trade-off between exploration (improving the surrogate) and exploitation (finding the minimizer of the surrogate and thus of the black-box function).\n",
    "\n",
    "The surrogate models - typically Gaussians processes (GP) or tree-based models (RF, GBT ...) - have their own parameters which are either estimated via maximum likelihood or are integrated out.\n",
    "For finding the maximum likelihood (ML) point typically a gradient-based local optimizer is used together with a heuristic such as multiple restarts.\n",
    "For integrating out the model parameters either Markov-chain Monte Carlo (MCMC) or approximate variational inference (VI) methods has to be used.  \n",
    "\n",
    "Various acquisition functions exist which either have a analytic form, or need to be approximated via Monte Carlo.\n",
    "In multi-objective BO the black-box function has multiple target outputs. Here the acquisition function needs to guide the search towards exploring the Pareto front.\n",
    "\n",
    "Search spaces define the possible inputs. When applying BO for tuning hyperparameters of machine learning models the inputs include continuous, integer / discrete and categorical variables and may include conditionals. When applying BO to optimization of real-world processes additional (in-)equality constraints may need to be satisfied.\n",
    "\n",
    "In each step of the BO loop the next point to evaluate is selected by finding the minimizer of the acquisition function over the search space.\n",
    "This is typically done using a gradient-free or gradient-based local optimizer or via MC-sampling, depending on the nature of the acquistion function.\n",
    "The search space including its constraints needs to be handled by the optimizer.\n",
    "\n",
    "There are a number of general-purpose (not focussing only on hyperparameter tuning) BO frameworks available in Python and R. In the main frameworks are compared in terms of supported features and development & support activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name | Surrogate | Hyperparameter handling | Acquisitions | Multi-objective | Search space | Optimizer |\n",
    "| ------------------------------------------------------------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------- | ---------------------------- | ----------------------------------------------- | --------------- | ---- |\n",
    "| [mlrMBO](https://mlr-org.github.io/mlrMBO) | GP, RF ([mlr](https://mlr.mlr-org.com/)) | ML | EI, CB, AEI, EQI, AdaCB | DIB | continuous, integer, categorical + constraints |\n",
    "| [pyGPGO](http://pygpgo.readthedocs.io) | GP (native), GBT, RF, ET ([scikit-learn](https://scikit-learn.org)) | ML, MCMC ([pymc3](https://docs.pymc.io/)) | EI, PI, CB | | continuous, integer |\n",
    "| [Scikit-Optimize](https://scikit-optimize.github.io) | GP, RF, GBT ([scikit-learn](https://scikit-learn.org)) | ML | EI, PI, CB | - | continuous, discrete, categorical + constraints | BFGS\n",
    "| [GPyOpt](https://github.com/SheffieldML/GPyOpt) | GP ([GPy](http://sheffieldml.github.io/GPy)) | ML, MCMC | EI, PI, CB | - | continuous, discrete, categorical + constraints | BFGS, DIRECT\n",
    "| [GPflowOpt](https://github.com/GPflow/GPflowOpt) | GP ([GPflow](https://github.com/GPflow/GPflow)) | ML | EI, PI, CB, MES, PF | HVPI | continuous |\n",
    "| [BoTorch](https://botorch.org/) | GP ([GPyTorch](https://github.com/cornellius-gp/gpytorch)) | MC, MCMC (Pyro)| | | |\n",
    "| [Emukit](https://github.com/amzn/emukit) | GP ([GPy](http://sheffieldml.github.io/GPy)) | ML | EI, PI, CB, ES, MES, PF | - | continuous, integer, categorical + constraints |\n",
    "| [DragonFly](https://github.com/dragonfly/dragonfly) | GP (native) | ML, posterior sampling | EI, CB, PI, TTEI, TS | scalarization with CB/TS | continuous, categorical | DOO, DIRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stars</th>\n      <th>forks</th>\n      <th>contributors</th>\n      <th>commits</th>\n      <th>open_issues</th>\n      <th>closed_issues</th>\n      <th>created</th>\n      <th>last_commit</th>\n      <th>license</th>\n    </tr>\n    <tr>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>scikit-optimize</th>\n      <td>1664</td>\n      <td>329</td>\n      <td>49</td>\n      <td>1229</td>\n      <td>166</td>\n      <td>671</td>\n      <td>2016-03-20</td>\n      <td>2020-02-04</td>\n      <td>BSD-3-Clause</td>\n    </tr>\n    <tr>\n      <th>mlrMBO</th>\n      <td>151</td>\n      <td>37</td>\n      <td>14</td>\n      <td>1583</td>\n      <td>82</td>\n      <td>401</td>\n      <td>2013-10-23</td>\n      <td>2020-02-07</td>\n      <td>NOASSERTION</td>\n    </tr>\n    <tr>\n      <th>botorch</th>\n      <td>1472</td>\n      <td>106</td>\n      <td>24</td>\n      <td>589</td>\n      <td>23</td>\n      <td>348</td>\n      <td>2018-07-30</td>\n      <td>2020-01-26</td>\n      <td>MIT</td>\n    </tr>\n    <tr>\n      <th>emukit</th>\n      <td>175</td>\n      <td>50</td>\n      <td>16</td>\n      <td>250</td>\n      <td>27</td>\n      <td>254</td>\n      <td>2018-09-04</td>\n      <td>2020-01-13</td>\n      <td>Apache-2.0</td>\n    </tr>\n    <tr>\n      <th>GPyOpt</th>\n      <td>570</td>\n      <td>168</td>\n      <td>32</td>\n      <td>487</td>\n      <td>76</td>\n      <td>221</td>\n      <td>2014-08-13</td>\n      <td>2019-12-02</td>\n      <td>BSD-3-Clause</td>\n    </tr>\n    <tr>\n      <th>GPflowOpt</th>\n      <td>199</td>\n      <td>41</td>\n      <td>5</td>\n      <td>426</td>\n      <td>22</td>\n      <td>97</td>\n      <td>2017-04-28</td>\n      <td>2018-09-12</td>\n      <td>Apache-2.0</td>\n    </tr>\n    <tr>\n      <th>dragonfly</th>\n      <td>459</td>\n      <td>48</td>\n      <td>7</td>\n      <td>341</td>\n      <td>14</td>\n      <td>44</td>\n      <td>2018-04-20</td>\n      <td>2019-12-30</td>\n      <td>MIT</td>\n    </tr>\n    <tr>\n      <th>pyGPGO</th>\n      <td>171</td>\n      <td>43</td>\n      <td>2</td>\n      <td>292</td>\n      <td>7</td>\n      <td>17</td>\n      <td>2016-11-23</td>\n      <td>2019-06-15</td>\n      <td>MIT</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                 stars  forks  contributors  commits  open_issues  \\\nname                                                                \nscikit-optimize   1664    329            49     1229          166   \nmlrMBO             151     37            14     1583           82   \nbotorch           1472    106            24      589           23   \nemukit             175     50            16      250           27   \nGPyOpt             570    168            32      487           76   \nGPflowOpt          199     41             5      426           22   \ndragonfly          459     48             7      341           14   \npyGPGO             171     43             2      292            7   \n\n                 closed_issues     created last_commit       license  \nname                                                                  \nscikit-optimize            671  2016-03-20  2020-02-04  BSD-3-Clause  \nmlrMBO                     401  2013-10-23  2020-02-07   NOASSERTION  \nbotorch                    348  2018-07-30  2020-01-26           MIT  \nemukit                     254  2018-09-04  2020-01-13    Apache-2.0  \nGPyOpt                     221  2014-08-13  2019-12-02  BSD-3-Clause  \nGPflowOpt                   97  2017-04-28  2018-09-12    Apache-2.0  \ndragonfly                   44  2018-04-20  2019-12-30           MIT  \npyGPGO                      17  2016-11-23  2019-06-15           MIT  "
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "df = util.compare_repos([\n",
    "    'mlr-org/mlrMBO',\n",
    "    'SheffieldML/GPyOpt',\n",
    "    'scikit-optimize/scikit-optimize',\n",
    "    'GPflow/GPflowOpt',\n",
    "    'pytorch/botorch',\n",
    "    'amzn/emukit',\n",
    "    'dragonfly/dragonfly',\n",
    "    'josejimenezluna/pyGPGO',\n",
    "])\n",
    "df.sort_values(by='closed_issues', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPyOpt\n",
    "* GPy [[code]](https://github.com/SheffieldML/GPy) [[doc]](https://gpy.readthedocs.io/en/latest/)\n",
    "* GPyOpt [[code]](https://github.com/SheffieldML/GPyOpt) [[doc]](https://gpyopt.readthedocs.io/en/latest/)\n",
    "\n",
    "GPyOpt is a BO package built on top of the hugely popular GPy for flexible GP modeling. Both are being developed by the university of Sheffield.\n",
    "Together with mlrMBO, GPyOpt has been around the longest. However, development of GPyOpt has somewhat stalled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Optimize\n",
    "[[code]](https://github.com/scikit-optimize/scikit-optimize)\n",
    "[[doc]](https://scikit-optimize.github.io/)\n",
    "\n",
    "Scikit-Optimize is a stable and well polished BO package based on the GP and tree-based models in Scikit-Learn. Not supported are model parameter integration and multi-objective optimization. Compared to GPy, the GP modeling in Scikit-Learn is rather rudimentary. Mixed search spaces and constraints are supported, as well as external, delayed and batched evaluations. For Hyperparameter tuning in Scikit-Learn there is a drop-in replacement for Grid/RandomSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPFlowOpt (with TF & GPFlow)\n",
    "* GPFlow [[code]](https://github.com/GPflow/GPflow) [[doc]](https://gpflow.readthedocs.io/en/latest/) [[paper]](https://arxiv.org/abs/1711.03845)\n",
    "* GPFlowOpt [[code]](https://github.com/GPflow/GPflowOpt) [[doc]](https://gpflowopt.readthedocs.io/en/latest/) [[paper]](http://jmlr.org/papers/v18/16-537.html)\n",
    "\n",
    "GPFlowOpt is BO package built on top of GPFlow, which in turn uses TensorFlow for fast linear algebra computations with GPU-support and auto-differentiation. This makes it more extensible as different models and acquisition functions can be implemented without having to define gradients for the optimizer.\n",
    "The top-level API is inspired GPy. Development of GPFlowOpt seems to have stopped completely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoTorch (with PyTorch, GPyTorch & Pyro)\n",
    "* BoTorch [[code]](https://github.com/pytorch/botorch) [[doc]](https://botorch.org/) [[paper]](https://arxiv.org/abs/1910.06403)\n",
    "* GPyTorch [[code]](https://github.com/cornellius-gp/gpytorch) [[doc]](https://gpytorch.ai/) [[paper]](https://arxiv.org/abs/1809.11165)\n",
    "* Pyro [[code]](https://github.com/pyro-ppl/pyro) [[doc]](http://docs.pyro.ai) [[paper]](https://arxiv.org/abs/1810.09538)\n",
    "\n",
    "BoTorch is BO package built on top of GPyTorch (GP modeling), Pyro (MCMC and variational inference) and PyTorch as its compution framework. Hence, as GPFlowOpt, it profits from native GPU support and auto-differentiation. BoTorch is still in its beta phase and several features such as MCMC integrated model parameters are not yet implemented. Activity on the github project is high though and it seems to have won over GPFlowOpt. BoTorch is extremely flexible, at the expense of requiring plently of boilerplate code and in-depth knowledge of PyTorch when using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emukit\n",
    "[[code]](https://github.com/amzn/emukit)\n",
    "[[doc]](https://amzn.github.io/emukit/)\n",
    "[[paper]]()\n",
    "\n",
    "Emukit is toolbox for BO and and Bayesian quadrature, developed by Amazon. It is intended to be independent of the modeling framework, but supports first class support for GPy. Similar built-in support for other frameworks is apparently not planned. Mixed search spaces and constraints are supported, multi-objective optimization is currently not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dragonfly\n",
    "[[code]](https://github.com/dragonfly/dragonfly)\n",
    "[[doc]](https://dragonfly-opt.readthedocs.io)\n",
    "[[paper]](https://arxiv.org/abs/1903.06694)\n",
    "\n",
    "Dragonfly is package developed at Carneggie Melon University. It has native implementations of GPs with the typical kernels, an optimizer (DOO), MCMC samplers copied from copied from pymc3 and pgmpy (Metropolis, Slice, NUTS, HMC). Multi-objective optimization is supported via random scalarizations, constraints are not.\n",
    "Note that Thompson sampling from GPs looks incorrectly implemented, as points are sampled without keeping track of the previously sampled points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other projects\n",
    "* [fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization) - Small BO package using GPs from Scikit-Learn \n",
    "* [Cornell-MOE](https://github.com/wujian16/Cornell-MOE) - Relatively old Python / C++ package for BO\n",
    "* [ProcessOptimizer](https://github.com/bytesandbrains/ProcessOptimizer) - Fork of Scikit-Optimizer for optimizing real world processes. Provides classes for composable constraints. However, only rejection sampling is implemented.\n",
    "* [Phoenics](https://github.com/aspuru-guzik-group/phoenics) - BO package using kernel density estimates and a specific multi-objective acquistion called CHIMERA\n",
    "* [TS-EMO](https://github.com/Eric-Bradford/TS-EMO) - Matlab implementation of the TS-EMO algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}