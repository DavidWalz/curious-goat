{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Optimization (BO) is a method for optimizing expensive black-box functions by means of a probabilistic surrogate model and an acquisition function that specifies a trade-off between exploration (improving the surrogate) and exploitation (finding the minimizer of the surrogate and thus of the black-box function).\n",
    "\n",
    "As **surrogate model** typically Gaussians processes (GP) or tree-based models (RF, GBT ...) are used. These have their own parameters that need to be estimated via maximum likelihood or integrated out.\n",
    "The maximum likelihood (ML) point estimate is typically searched using a gradient-based local optimizer is used together with a heuristic such as multiple restarts to deal with the non-convexiy of the problem.\n",
    "For integrating out the model parameters either Markov-chain Monte Carlo (MCMC) or approximate variational inference (VI) methods have to be used, together with an assumption on the prior distribution. As with the ML estimation, the problem is non-convex.\n",
    "\n",
    "**Search spaces** define the possible inputs. When applying BO for tuning hyperparameters of machine learning models the inputs include continuous, integer / ordinal and categorical variables and may include conditionals. When applying BO to optimization of real-world processes additional (in-)equality constraints may need to be satisfied.\n",
    "\n",
    "**Acquistion functions** either have a analytic form, or need to be approximated via Monte Carlo methods.\n",
    "We want to find the minimizer of the acquistion over the search space in order to evaluate it next.\n",
    "This is typically done using a gradient-free or gradient-based local optimizer or via MC-sampling, depending on the nature of the acquistion function.\n",
    "The search space including its constraints needs to be handled by the optimizer.\n",
    "In multi-objective BO the black-box function has multiple target outputs. Here the acquisition function needs to guide the search towards exploring the Pareto front.  \n",
    "\n",
    "There are a number of general-purpose (not focussing only on hyperparameter tuning) BO frameworks available in Python and R. In the main frameworks are compared in terms of supported features and development & support activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature comparison\n",
    "This table is work in progress ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name | Surrogate | Hyperparameter handling | Acquisitions | Multi-objective | Search space | Optimizer |\n",
    "| ------------------------------------------------------------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------- | ---------------------------- | ----------------------------------------------- | --------------- | ---- |\n",
    "| [mlrMBO](https://mlr-org.github.io/mlrMBO) | GP, RF ([mlr](https://mlr.mlr-org.com/)) | ML | EI, CB, AEI, EQI, AdaCB | DIB | continuous, integer, categorical + constraints |\n",
    "| [pyGPGO](http://pygpgo.readthedocs.io) | GP (native), GBT, RF, ET ([scikit-learn](https://scikit-learn.org)) | ML, MCMC ([pymc3](https://docs.pymc.io/)) | EI, PI, CB | | continuous, integer |\n",
    "| [Scikit-Optimize](https://scikit-optimize.github.io) | GP, RF, GBT ([scikit-learn](https://scikit-learn.org)) | ML | EI, PI, CB | - | continuous, discrete, categorical + constraints | BFGS\n",
    "| [GPyOpt](https://github.com/SheffieldML/GPyOpt) | GP ([GPy](http://sheffieldml.github.io/GPy)) | ML, MCMC | EI, PI, CB | - | continuous, discrete, categorical + constraints | BFGS, DIRECT\n",
    "| [GPflowOpt](https://github.com/GPflow/GPflowOpt) | GP ([GPflow](https://github.com/GPflow/GPflow)) | ML | EI, PI, CB, MES, PF | HVPI | continuous |\n",
    "| [BoTorch](https://botorch.org/) | GP ([GPyTorch](https://github.com/cornellius-gp/gpytorch)) | MC, MCMC (Pyro)| GP-EI, GP-PI, GP-CB, KG, extendible | | |\n",
    "| [Emukit](https://github.com/amzn/emukit) | GP ([GPy](http://sheffieldml.github.io/GPy)) | ML | EI, PI, CB, ES, MES, PF | - | continuous, integer, categorical + constraints |\n",
    "| [DragonFly](https://github.com/dragonfly/dragonfly) | GP (native) | ML, posterior sampling | EI, CB, PI, TTEI, TS | scalarization with CB/TS | continuous, categorical | DOO, DIRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity comparison\n",
    "The ranking by open/closed issues and commits gives similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-07 07:21:47.478388\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>forks</th>\n",
       "      <th>contributors</th>\n",
       "      <th>commits</th>\n",
       "      <th>open_issues</th>\n",
       "      <th>closed_issues</th>\n",
       "      <th>created</th>\n",
       "      <th>last_commit</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scikit-optimize</th>\n",
       "      <td>1727</td>\n",
       "      <td>337</td>\n",
       "      <td>54</td>\n",
       "      <td>1491</td>\n",
       "      <td>134</td>\n",
       "      <td>763</td>\n",
       "      <td>2016-03-20</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>BSD-3-Clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlrMBO</th>\n",
       "      <td>157</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>1590</td>\n",
       "      <td>85</td>\n",
       "      <td>403</td>\n",
       "      <td>2013-10-23</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>NOASSERTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>botorch</th>\n",
       "      <td>1541</td>\n",
       "      <td>122</td>\n",
       "      <td>25</td>\n",
       "      <td>622</td>\n",
       "      <td>22</td>\n",
       "      <td>394</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ax</th>\n",
       "      <td>1087</td>\n",
       "      <td>98</td>\n",
       "      <td>42</td>\n",
       "      <td>501</td>\n",
       "      <td>16</td>\n",
       "      <td>272</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emukit</th>\n",
       "      <td>190</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>260</td>\n",
       "      <td>25</td>\n",
       "      <td>264</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>Apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPyOpt</th>\n",
       "      <td>587</td>\n",
       "      <td>173</td>\n",
       "      <td>35</td>\n",
       "      <td>504</td>\n",
       "      <td>82</td>\n",
       "      <td>231</td>\n",
       "      <td>2014-08-13</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>BSD-3-Clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPflowOpt</th>\n",
       "      <td>204</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>426</td>\n",
       "      <td>22</td>\n",
       "      <td>97</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>Apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dragonfly</th>\n",
       "      <td>475</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>393</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pyGPGO</th>\n",
       "      <td>171</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>292</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>2016-11-23</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 stars  forks  contributors  commits  open_issues  \\\n",
       "name                                                                \n",
       "scikit-optimize   1727    337            54     1491          134   \n",
       "mlrMBO             157     38            14     1590           85   \n",
       "botorch           1541    122            25      622           22   \n",
       "Ax                1087     98            42      501           16   \n",
       "emukit             190     58            18      260           25   \n",
       "GPyOpt             587    173            35      504           82   \n",
       "GPflowOpt          204     46             5      426           22   \n",
       "dragonfly          475     53             8      393           14   \n",
       "pyGPGO             171     43             2      292            7   \n",
       "\n",
       "                 closed_issues     created last_commit       license  \n",
       "name                                                                  \n",
       "scikit-optimize            763  2016-03-20  2020-03-26  BSD-3-Clause  \n",
       "mlrMBO                     403  2013-10-23  2020-03-09   NOASSERTION  \n",
       "botorch                    394  2018-07-30  2020-04-06           MIT  \n",
       "Ax                         272  2019-02-09  2020-04-06           MIT  \n",
       "emukit                     264  2018-09-04  2020-04-06    Apache-2.0  \n",
       "GPyOpt                     231  2014-08-13  2020-03-19  BSD-3-Clause  \n",
       "GPflowOpt                   97  2017-04-28  2018-09-12    Apache-2.0  \n",
       "dragonfly                   49  2018-04-20  2020-03-13           MIT  \n",
       "pyGPGO                      17  2016-11-23  2019-06-15           MIT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "df = util.compare_repos([\n",
    "    'mlr-org/mlrMBO',\n",
    "    'SheffieldML/GPyOpt',\n",
    "    'scikit-optimize/scikit-optimize',\n",
    "    'GPflow/GPflowOpt',\n",
    "    'pytorch/botorch',\n",
    "    'amzn/emukit',\n",
    "    'dragonfly/dragonfly',\n",
    "    'josejimenezluna/pyGPGO',\n",
    "    'facebook/Ax'\n",
    "])\n",
    "df.sort_values(by='closed_issues', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPyOpt\n",
    "* GPy [[code]](https://github.com/SheffieldML/GPy) [[doc]](https://gpy.readthedocs.io/en/latest/)\n",
    "* GPyOpt [[code]](https://github.com/SheffieldML/GPyOpt) [[doc]](https://gpyopt.readthedocs.io/en/latest/)\n",
    "\n",
    "GPyOpt is a BO package built on top of the hugely popular GPy for flexible GP modeling. Both are being developed by the university of Sheffield.\n",
    "Together with mlrMBO, GPyOpt has been around the longest. However, development of GPyOpt has somewhat stalled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Optimize\n",
    "[[code]](https://github.com/scikit-optimize/scikit-optimize)\n",
    "[[doc]](https://scikit-optimize.github.io/)\n",
    "\n",
    "Scikit-Optimize is an actively developed and well polished BO package based on the GP and tree-based models in Scikit-Learn. Not supported are model parameter integration and multi-objective optimization. Compared to GPy, the GP modeling in Scikit-Learn is rather rudimentary. Mixed search spaces and constraints are supported, as well as external, delayed and batched evaluations. For Hyperparameter tuning in Scikit-Learn there is a drop-in replacement for Grid/RandomSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPFlowOpt (with TF & GPFlow)\n",
    "* GPFlow [[code]](https://github.com/GPflow/GPflow) [[doc]](https://gpflow.readthedocs.io/en/latest/) [[paper]](https://arxiv.org/abs/1711.03845)\n",
    "* GPFlowOpt [[code]](https://github.com/GPflow/GPflowOpt) [[doc]](https://gpflowopt.readthedocs.io/en/latest/) [[paper]](http://jmlr.org/papers/v18/16-537.html)\n",
    "\n",
    "GPFlowOpt is BO package built on top of GPFlow, which in turn uses TensorFlow for fast linear algebra computations with GPU-support and auto-differentiation. This makes it more extensible as different models and acquisition functions can be implemented without having to define gradients for the optimizer.\n",
    "The top-level API is inspired GPy.\n",
    "\n",
    "*Development on GPFlowOpt seems to have stopped completely.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoTorch (with PyTorch, GPyTorch & Pyro)\n",
    "* BoTorch [[code]](https://github.com/pytorch/botorch) [[doc]](https://botorch.org/) [[paper]](https://arxiv.org/abs/1910.06403)\n",
    "* GPyTorch [[code]](https://github.com/cornellius-gp/gpytorch) [[doc]](https://gpytorch.ai/) [[paper]](https://arxiv.org/abs/1809.11165)\n",
    "* Pyro [[code]](https://github.com/pyro-ppl/pyro) [[doc]](http://docs.pyro.ai) [[paper]](https://arxiv.org/abs/1810.09538)\n",
    "\n",
    "BoTorch is a BO package built on top of GPyTorch (GP modeling), Pyro (MCMC and variational inference) and PyTorch as its compution framework. Hence, as GPFlowOpt, it profits from native GPU support and auto-differentiation. BoTorch is still in its beta phase and several features such as MCMC integrated model parameters are not yet implemented. Activity on the github project is high though and it seems to have won over GPFlowOpt. BoTorch is extremely flexible, at the expense of requiring plently of boilerplate code and in-depth knowledge of PyTorch when extending it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ax\n",
    "[[code]](https://github.com/facebook/Ax)\n",
    "[[doc]](https://ax.dev)\n",
    "[[test]](ax.ipynb)\n",
    "\n",
    "Ax is a high-level framework for Bayesian and Bandit optimization. \n",
    "For BO, Ax relies mostly on BoTorch from the same developers. \n",
    "For Bandits optimization, Thompson sampling is used.\n",
    "Ax provides:\n",
    "* a service-like API for managing and storing experiments as JSON files (local) or in SQL databases. The service is only running locally.\n",
    "* transform pipelines to handle encoding of categorical and ordinal variables, scaling and log-transforms\n",
    "* limited support for parameter constraints of type $x1 \\leq x2$ and $\\sum x \\leq c$ as well as output constraints\n",
    "* limited support for multi-objective optimization: only weighted sum scalarization and no tooling around it\n",
    "* plot functions using plotly\n",
    "* examples for human-in-the-loop optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emukit\n",
    "[[code]](https://github.com/amzn/emukit)\n",
    "[[doc]](https://amzn.github.io/emukit/)\n",
    "[[paper]]()\n",
    "\n",
    "Emukit is a high-level framework for Bayesian optimization and and Bayesian quadrature. It is intended to be independent of the modeling framework, but supports first class support for GPy. Similar built-in support for other frameworks is apparently not planned. Mixed search spaces and constraints are supported, multi-objective optimization is currently not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dragonfly\n",
    "[[code]](https://github.com/dragonfly/dragonfly)\n",
    "[[doc]](https://dragonfly-opt.readthedocs.io)\n",
    "[[paper]](https://arxiv.org/abs/1903.06694)\n",
    "\n",
    "Dragonfly is package developed at Carneggie Melon University. It has native implementations of GPs with the typical kernels, an optimizer (DOO), MCMC samplers copied from copied from pymc3 and pgmpy (Metropolis, Slice, NUTS, HMC). Multi-objective optimization is supported via random scalarizations, constraints are not.\n",
    "Note that Thompson sampling from GPs seems to be incorrectly implemented, as points are sampled without keeping track of the previously sampled points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other projects\n",
    "* [fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization) - Small BO package using GPs from Scikit-Learn \n",
    "* [Cornell-MOE](https://github.com/wujian16/Cornell-MOE) - Relatively old Python / C++ package for BO\n",
    "* [ProcessOptimizer](https://github.com/bytesandbrains/ProcessOptimizer) - Fork of Scikit-Optimizer for optimizing real world processes. Provides classes for composable constraints. However, only rejection sampling is implemented.\n",
    "* [Phoenics](https://github.com/aspuru-guzik-group/phoenics) - BO package using kernel density estimates and a specific multi-objective acquistion called CHIMERA\n",
    "* [TS-EMO](https://github.com/Eric-Bradford/TS-EMO) - Matlab implementation of the TS-EMO algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
